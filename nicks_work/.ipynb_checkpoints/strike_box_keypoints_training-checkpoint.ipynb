{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f253a47-3d17-45bf-be19-a35b708af3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: roboflow in /home/niquach/.local/lib/python3.11/site-packages (1.1.54)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from roboflow) (2024.8.30)\n",
      "Requirement already satisfied: idna==3.7 in /opt/conda/lib/python3.11/site-packages (from roboflow) (3.7)\n",
      "Requirement already satisfied: cycler in /opt/conda/lib/python3.11/site-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from roboflow) (1.4.5)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (from roboflow) (3.8.4)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.11/site-packages (from roboflow) (1.26.4)\n",
      "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /home/niquach/.local/lib/python3.11/site-packages (from roboflow) (4.10.0.84)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /opt/conda/lib/python3.11/site-packages (from roboflow) (10.4.0)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.11/site-packages (from roboflow) (2.9.0)\n",
      "Requirement already satisfied: python-dotenv in /home/niquach/.local/lib/python3.11/site-packages (from roboflow) (1.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from roboflow) (2.32.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /opt/conda/lib/python3.11/site-packages (from roboflow) (2.2.1)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.11/site-packages (from roboflow) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.11/site-packages (from roboflow) (6.0.1)\n",
      "Requirement already satisfied: requests-toolbelt in /home/niquach/.local/lib/python3.11/site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: filetype in /home/niquach/.local/lib/python3.11/site-packages (from roboflow) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib->roboflow) (1.2.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib->roboflow) (4.51.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib->roboflow) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib->roboflow) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->roboflow) (3.3.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ultralytics in /home/niquach/.local/lib/python3.11/site-packages (8.3.85)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (3.8.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (1.13.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (2.2.1+cu121)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (0.17.1+cu121)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from ultralytics) (5.9.8)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.11/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /home/niquach/.local/lib/python3.11/site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2118d5f7-69f9-47dc-b2b0-bcfbf39ac3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be9771f9-4dbb-421b-a904-fdc2a2a0dc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273731e6-8ce3-4745-9d59-9f0ebc9958cd",
   "metadata": {},
   "source": [
    "## Baseball Detection Model #2 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d5e2430-e244-4718-be31-80f9797b33bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in baseball-5 to yolov5pytorch:: 100%|██████████| 276251/276251 [00:06<00:00, 45029.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to baseball-5 in yolov5pytorch:: 100%|██████████| 14412/14412 [00:11<00:00, 1298.47it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"mRglaGKqbUaqYkRNW8fk\")\n",
    "project = rf.workspace(\"baseball-0zxv7\").project(\"baseball-0vbbm\")\n",
    "version = project.version(5)\n",
    "dataset = version.download(\"yolov5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90085538-8117-43ac-be91-1c847608bde2",
   "metadata": {},
   "source": [
    "## Baseball Detection Model #2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0578b42-1290-449f-984b-a00fbad251cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.89 available 😃 Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov5su.pt, data=../nicks_work/baseball-5/data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=540, save=True, save_period=-1, cache=False, device=cuda:0, workers=8, project=None, name=train15, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train15\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \n",
      " 24        [17, 20, 23]  1   2117983  ultralytics.nn.modules.head.Detect           [5, [128, 256, 512]]          \n",
      "YOLOv5s summary: 153 layers, 9,124,127 parameters, 9,124,111 gradients, 24.1 GFLOPs\n",
      "\n",
      "Transferred 421/427 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train15', view at http://localhost:6006/\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "WARNING ⚠️ imgsz=[540] must be multiple of max stride 32, updating to [544]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/niquach/private/AI-Pitch-Recognition/nicks_work/baseball-5/train/labels.cache... 6308 images, 293 backgrounds, 0 corrupt: 100%|██████████| 6308/6308 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 7926, len(boxes) = 28465. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/niquach/private/AI-Pitch-Recognition/nicks_work/baseball-5/valid/labels.cache... 592 images, 36 backgrounds, 0 corrupt: 100%|██████████| 592/592 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 596, len(boxes) = 2695. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train15/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 544 train, 544 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train15\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10       3.5G      1.838      2.432      1.251         60        544:  76%|███████▋  | 302/395 [01:16<00:23,  3.96it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov5su.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# baseball model = model = YOLO(\"../runs/detect/train13/weights/best.pt\").to(device)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../nicks_work/baseball-5/data.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m540\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/ultralytics/engine/model.py:810\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 810\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/ultralytics/engine/trainer.py:208\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/ultralytics/engine/trainer.py:381\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp):\n\u001b[1;32m    380\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_batch(batch)\n\u001b[0;32m--> 381\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    383\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m world_size\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/ultralytics/nn/tasks.py:113\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03mPerform forward pass of the model for either training or inference.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m    (torch.Tensor): Loss if x is a dict (training), or network predictions (inference).\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/ultralytics/nn/tasks.py:291\u001b[0m, in \u001b[0;36mBaseModel.loss\u001b[0;34m(self, batch, preds)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_criterion()\n\u001b[0;32m--> 291\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m preds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m preds\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(preds, batch)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/ultralytics/nn/tasks.py:114\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/ultralytics/nn/tasks.py:132\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[0;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/ultralytics/nn/tasks.py:153\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m--> 153\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m    154\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/ultralytics/nn/modules/block.py:264\u001b[0m, in \u001b[0;36mC3.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    263\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through the CSP bottleneck with 2 convolutions.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/ultralytics/nn/modules/conv.py:51\u001b[0m, in \u001b[0;36mConv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply convolution, batch normalization and activation to input tensor.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO, settings\n",
    "\n",
    "settings.update({\"datasets_dir\": \"/home/niquach/private/AI-Pitch-Recognition/nicks_work\"})\n",
    "# private/AI-Pitch-Recognition/baseball-detection-2-4/baseball-detection-2-4\n",
    "\n",
    "# Load model\n",
    "model = YOLO(\"yolov5su.pt\").to(device)\n",
    "# baseball model = model = YOLO(\"../runs/detect/train13/weights/best.pt\").to(device)\n",
    "\n",
    "# Train model\n",
    "model.train(\n",
    "    data=\"../nicks_work/baseball-5/data.yaml\",\n",
    "    epochs=10,\n",
    "    imgsz=540,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f73a6f-81c2-4756-bafa-19a257dc7c9c",
   "metadata": {},
   "source": [
    "## Batter and Home Plate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51783bde-7702-48f4-919d-2da4f4b698cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in batter-and-home-plate-1 to yolov5pytorch:: 100%|██████████| 22744/22744 [00:01<00:00, 20806.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to batter-and-home-plate-1 in yolov5pytorch:: 100%|██████████| 940/940 [00:00<00:00, 1666.49it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"mRglaGKqbUaqYkRNW8fk\")\n",
    "project = rf.workspace(\"chaesubin\").project(\"batter-and-home-plate\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov5\")            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dbf371-d1bc-4c21-bdb8-193bc8f754f3",
   "metadata": {},
   "source": [
    "## Batter and Home Plate Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7457abc2-653d-46a1-afb3-7c9293a1ea4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO, settings\n",
    "\n",
    "settings.update({\"datasets_dir\": \"/home/niquach/private/AI-Pitch-Recognition/nicks_work\"})\n",
    "# private/AI-Pitch-Recognition/baseball-detection-2-4/baseball-detection-2-4\n",
    "\n",
    "# Load model\n",
    "model = YOLO(\"yolov5su.pt\").to(device)\n",
    "# baseball model = model = YOLO(\"../runs/detect/train13/weights/best.pt\").to(device)\n",
    "\n",
    "# Train model\n",
    "model.train(\n",
    "    data=\"../nicks_work/batter-and-home-plate-1/data.yaml\",\n",
    "    epochs=100,\n",
    "    imgsz=540,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b263035-9574-4159-963f-3b3671cf85e7",
   "metadata": {},
   "source": [
    "## Baseball Detection Model Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5689873-41e4-4a00-949b-bac55c30b8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_test2.jpg: 544x544 1 baseball, 11.8ms\n",
      "Speed: 2.7ms preprocess, 11.8ms inference, 5.6ms postprocess per image at shape (1, 3, 544, 544)\n",
      "Results saved to \u001b[1mruns/detect/track3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"../runs/detect/train13/weights/best.pt\")\n",
    "# results = model.predict(source=\"baseball-detection-2-4/baseball-detection-2-4/test/images/0eb9ef3c-255_jpg.rf.a9da7151055bf3395bedbdc72c61c4e3.jpg\", task=\"detect\", save=True)\n",
    "results = model.track(source=\"pitch_test2.jpg\", task=\"detect\", save=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05063558-f3a6-404b-9b6f-119073986a2d",
   "metadata": {},
   "source": [
    "## Batter and Home Plate Model Predict Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cb9d0e5-830a-4f6e-9082-a94de89d814f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_test2.jpg: 544x544 1 batter, 1 home plate, 12.5ms\n",
      "Speed: 2.9ms preprocess, 12.5ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 544)\n",
      "Results saved to \u001b[1mruns/detect/track4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"runs/detect/train12/weights/best.pt\")\n",
    "# results = model.predict(source=\"baseball-detection-2-4/baseball-detection-2-4/test/images/0eb9ef3c-255_jpg.rf.a9da7151055bf3395bedbdc72c61c4e3.jpg\", task=\"detect\", save=True)\n",
    "results = model.track(source=\"pitch_test2.jpg\", task=\"detect\", save=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf9291b-032e-4529-98ff-afc2a15a622b",
   "metadata": {},
   "source": [
    "## Batter and Home Plate Model Predict Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a63b050-88de-42c6-9f03-abc32133a814",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING ⚠️ inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 14.4ms\n",
      "video 1/1 (frame 2/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 10.6ms\n",
      "video 1/1 (frame 3/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 10.1ms\n",
      "video 1/1 (frame 4/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 10.2ms\n",
      "video 1/1 (frame 5/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 9.9ms\n",
      "video 1/1 (frame 6/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 10.2ms\n",
      "video 1/1 (frame 7/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 10.0ms\n",
      "video 1/1 (frame 8/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 9.8ms\n",
      "video 1/1 (frame 9/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 10.1ms\n",
      "video 1/1 (frame 10/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 10.4ms\n",
      "video 1/1 (frame 11/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 10.4ms\n",
      "video 1/1 (frame 12/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 10.3ms\n",
      "video 1/1 (frame 13/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 9.8ms\n",
      "video 1/1 (frame 14/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 9.8ms\n",
      "video 1/1 (frame 15/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 10.3ms\n",
      "video 1/1 (frame 16/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 10.3ms\n",
      "video 1/1 (frame 17/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 10.4ms\n",
      "video 1/1 (frame 18/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 10.5ms\n",
      "video 1/1 (frame 19/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 10.0ms\n",
      "video 1/1 (frame 20/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 9.8ms\n",
      "video 1/1 (frame 21/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 10.0ms\n",
      "video 1/1 (frame 22/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 10.5ms\n",
      "video 1/1 (frame 23/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 10.3ms\n",
      "video 1/1 (frame 24/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 10.1ms\n",
      "video 1/1 (frame 25/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 9.9ms\n",
      "video 1/1 (frame 26/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 10.3ms\n",
      "video 1/1 (frame 27/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 10.8ms\n",
      "video 1/1 (frame 28/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 11.1ms\n",
      "video 1/1 (frame 29/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 10.3ms\n",
      "video 1/1 (frame 30/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 10.2ms\n",
      "video 1/1 (frame 31/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 10.8ms\n",
      "video 1/1 (frame 32/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 9.9ms\n",
      "video 1/1 (frame 33/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 10.4ms\n",
      "video 1/1 (frame 34/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 10.6ms\n",
      "video 1/1 (frame 35/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 10.9ms\n",
      "video 1/1 (frame 36/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 10.7ms\n",
      "video 1/1 (frame 37/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 9.9ms\n",
      "video 1/1 (frame 38/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 9.8ms\n",
      "video 1/1 (frame 39/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 2 batters, 1 home plate, 10.0ms\n",
      "video 1/1 (frame 40/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 10.2ms\n",
      "video 1/1 (frame 41/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 10.8ms\n",
      "video 1/1 (frame 42/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 10.0ms\n",
      "video 1/1 (frame 43/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 10.0ms\n",
      "video 1/1 (frame 44/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 10.6ms\n",
      "video 1/1 (frame 45/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 9.9ms\n",
      "video 1/1 (frame 46/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 9.8ms\n",
      "video 1/1 (frame 47/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 9.9ms\n",
      "video 1/1 (frame 48/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 9.9ms\n",
      "video 1/1 (frame 49/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 10.2ms\n",
      "video 1/1 (frame 50/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 10.1ms\n",
      "video 1/1 (frame 51/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 10.3ms\n",
      "video 1/1 (frame 52/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 10.3ms\n",
      "video 1/1 (frame 53/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 9.8ms\n",
      "video 1/1 (frame 54/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 10.4ms\n",
      "video 1/1 (frame 55/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 10.1ms\n",
      "video 1/1 (frame 56/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 10.0ms\n",
      "video 1/1 (frame 57/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 10.4ms\n",
      "video 1/1 (frame 58/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 10.7ms\n",
      "video 1/1 (frame 59/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 10.3ms\n",
      "video 1/1 (frame 60/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 10.6ms\n",
      "video 1/1 (frame 61/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 9.8ms\n",
      "video 1/1 (frame 62/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 1 home plate, 9.9ms\n",
      "video 1/1 (frame 63/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 11.6ms\n",
      "video 1/1 (frame 64/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 9.7ms\n",
      "video 1/1 (frame 65/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 9.8ms\n",
      "video 1/1 (frame 66/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 10.0ms\n",
      "video 1/1 (frame 67/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 9.9ms\n",
      "video 1/1 (frame 68/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 11.2ms\n",
      "video 1/1 (frame 69/69) /home/niquach/private/AI-Pitch-Recognition/nicks_work/pitch_vid_test3.mp4: 320x544 1 batter, 10.5ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 544)\n",
      "Results saved to \u001b[1mruns/detect/track7\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO, settings\n",
    "\n",
    "model = YOLO(\"runs/detect/train12/weights/best.pt\")\n",
    "\n",
    "result = model.track('pitch_vid_test3.mp4',conf=0.2, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c381a2f8-76ae-4ee3-bde8-d2b4df1ed236",
   "metadata": {},
   "source": [
    "## Predict Strike Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e65f834c-4c86-4d3a-aa9b-1e305b23232f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting filterpy\n",
      "  Downloading filterpy-1.4.5.zip (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from filterpy) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from filterpy) (1.13.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (from filterpy) (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib->filterpy) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib->filterpy) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib->filterpy) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib->filterpy) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib->filterpy) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib->filterpy) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib->filterpy) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib->filterpy) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->filterpy) (1.16.0)\n",
      "Building wheels for collected packages: filterpy\n",
      "  Building wheel for filterpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110458 sha256=817fac689c7538dcf39dfde4d779bd1aa3219842f2bf25fc958bc7ba14616846\n",
      "  Stored in directory: /home/niquach/.cache/pip/wheels/12/dc/3c/e12983eac132d00f82a20c6cbe7b42ce6e96190ef8fa2d15e1\n",
      "Successfully built filterpy\n",
      "Installing collected packages: filterpy\n",
      "Successfully installed filterpy-1.4.5\n"
     ]
    }
   ],
   "source": [
    "!pip install filterpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c541e7d0-8577-40bf-895f-ef2b7085f5b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x544 2 batters, 1 home plate, 14.3ms\n",
      "Speed: 2.2ms preprocess, 14.3ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 77.1ms\n",
      "Speed: 3.1ms preprocess, 77.1ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 11.1ms\n",
      "Speed: 2.1ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 12.4ms\n",
      "Speed: 4.0ms preprocess, 12.4ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 10.5ms\n",
      "Speed: 1.9ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 12.5ms\n",
      "Speed: 2.9ms preprocess, 12.5ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 11.0ms\n",
      "Speed: 1.8ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 12.4ms\n",
      "Speed: 3.0ms preprocess, 12.4ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 12.4ms\n",
      "Speed: 1.9ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 12.4ms\n",
      "Speed: 3.2ms preprocess, 12.4ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 10.6ms\n",
      "Speed: 1.9ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 12.5ms\n",
      "Speed: 2.9ms preprocess, 12.5ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 11.9ms\n",
      "Speed: 1.7ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 12.4ms\n",
      "Speed: 2.9ms preprocess, 12.4ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 11.1ms\n",
      "Speed: 2.6ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 12.4ms\n",
      "Speed: 3.0ms preprocess, 12.4ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 11.2ms\n",
      "Speed: 1.9ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 12.4ms\n",
      "Speed: 3.3ms preprocess, 12.4ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 10.9ms\n",
      "Speed: 1.9ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 12.4ms\n",
      "Speed: 2.9ms preprocess, 12.4ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 10.9ms\n",
      "Speed: 1.8ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 12.4ms\n",
      "Speed: 3.2ms preprocess, 12.4ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 12.2ms\n",
      "Speed: 1.9ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 12.9ms\n",
      "Speed: 3.7ms preprocess, 12.9ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 12.3ms\n",
      "Speed: 2.0ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 12.1ms\n",
      "Speed: 3.3ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 12.3ms\n",
      "Speed: 1.9ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 12.2ms\n",
      "Speed: 3.4ms preprocess, 12.2ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 12.3ms\n",
      "Speed: 2.0ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 12.0ms\n",
      "Speed: 3.2ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 12.5ms\n",
      "Speed: 2.8ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 13.2ms\n",
      "Speed: 3.9ms preprocess, 13.2ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 12.4ms\n",
      "Speed: 2.1ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 12.2ms\n",
      "Speed: 3.6ms preprocess, 12.2ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 12.3ms\n",
      "Speed: 2.1ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 12.1ms\n",
      "Speed: 4.2ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 15.4ms\n",
      "Speed: 2.8ms preprocess, 15.4ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 13.7ms\n",
      "Speed: 5.5ms preprocess, 13.7ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 10.4ms\n",
      "Speed: 1.8ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 11.7ms\n",
      "Speed: 3.1ms preprocess, 11.7ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 14.3ms\n",
      "Speed: 2.8ms preprocess, 14.3ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 13.4ms\n",
      "Speed: 4.9ms preprocess, 13.4ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 2 home plates, 14.5ms\n",
      "Speed: 2.7ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 12.5ms\n",
      "Speed: 3.5ms preprocess, 12.5ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 1 home plate, 12.4ms\n",
      "Speed: 2.6ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 12.0ms\n",
      "Speed: 3.6ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 1 home plate, 12.5ms\n",
      "Speed: 2.7ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 11.8ms\n",
      "Speed: 3.6ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 2 home plates, 14.4ms\n",
      "Speed: 2.7ms preprocess, 14.4ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 13.9ms\n",
      "Speed: 3.9ms preprocess, 13.9ms inference, 0.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 2 home plates, 12.9ms\n",
      "Speed: 2.5ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 12.0ms\n",
      "Speed: 3.6ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 2 home plates, 12.3ms\n",
      "Speed: 2.4ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 11.9ms\n",
      "Speed: 3.6ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 2 home plates, 12.3ms\n",
      "Speed: 2.6ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 11.7ms\n",
      "Speed: 3.7ms preprocess, 11.7ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 10.4ms\n",
      "Speed: 2.1ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 11.7ms\n",
      "Speed: 3.2ms preprocess, 11.7ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 10.8ms\n",
      "Speed: 2.2ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 11.7ms\n",
      "Speed: 3.2ms preprocess, 11.7ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 10.5ms\n",
      "Speed: 2.3ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 11.8ms\n",
      "Speed: 3.1ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 10.7ms\n",
      "Speed: 1.7ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 11.7ms\n",
      "Speed: 2.9ms preprocess, 11.7ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 10.5ms\n",
      "Speed: 1.8ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 11.7ms\n",
      "Speed: 3.3ms preprocess, 11.7ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 10.4ms\n",
      "Speed: 1.7ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 11.7ms\n",
      "Speed: 3.1ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 11.6ms\n",
      "Speed: 1.9ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 11.7ms\n",
      "Speed: 3.5ms preprocess, 11.7ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 1 home plate, 10.5ms\n",
      "Speed: 1.8ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 11.8ms\n",
      "Speed: 3.0ms preprocess, 11.8ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 1 home plate, 10.4ms\n",
      "Speed: 1.8ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 11.7ms\n",
      "Speed: 2.8ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 2 home plates, 10.5ms\n",
      "Speed: 1.6ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 11.8ms\n",
      "Speed: 3.4ms preprocess, 11.8ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 2 batters, 2 home plates, 10.6ms\n",
      "Speed: 1.9ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 11.1ms\n",
      "Speed: 3.0ms preprocess, 11.1ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 2 home plates, 10.3ms\n",
      "Speed: 1.8ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 22.2ms\n",
      "Speed: 3.0ms preprocess, 22.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 2 home plates, 13.1ms\n",
      "Speed: 2.5ms preprocess, 13.1ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 11.1ms\n",
      "Speed: 3.3ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 2 home plates, 11.1ms\n",
      "Speed: 1.9ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 11.1ms\n",
      "Speed: 2.9ms preprocess, 11.1ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 2 home plates, 10.6ms\n",
      "Speed: 1.6ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 11.1ms\n",
      "Speed: 2.9ms preprocess, 11.1ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 2 home plates, 10.4ms\n",
      "Speed: 1.8ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 13.3ms\n",
      "Speed: 3.7ms preprocess, 13.3ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 1 home plate, 11.0ms\n",
      "Speed: 1.9ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 1 baseball, 11.2ms\n",
      "Speed: 3.6ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 1 home plate, 10.7ms\n",
      "Speed: 1.7ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 10.9ms\n",
      "Speed: 3.1ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 1 home plate, 10.4ms\n",
      "Speed: 1.8ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 10.9ms\n",
      "Speed: 3.2ms preprocess, 10.9ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 1 home plate, 12.0ms\n",
      "Speed: 1.8ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 10.9ms\n",
      "Speed: 3.2ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 1 home plate, 10.8ms\n",
      "Speed: 1.7ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 1 baseball, 10.9ms\n",
      "Speed: 2.8ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 1 home plate, 10.8ms\n",
      "Speed: 1.7ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 10.9ms\n",
      "Speed: 3.4ms preprocess, 10.9ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 1 home plate, 10.2ms\n",
      "Speed: 1.7ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 10.9ms\n",
      "Speed: 2.9ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 1 home plate, 13.1ms\n",
      "Speed: 1.7ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 10.9ms\n",
      "Speed: 3.0ms preprocess, 10.9ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 1 home plate, 10.8ms\n",
      "Speed: 1.7ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 10.9ms\n",
      "Speed: 3.0ms preprocess, 10.9ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 1 home plate, 10.7ms\n",
      "Speed: 1.6ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 1 baseball, 11.6ms\n",
      "Speed: 2.8ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 1 home plate, 11.3ms\n",
      "Speed: 1.8ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 2 baseballs, 10.8ms\n",
      "Speed: 3.7ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 1 home plate, 10.4ms\n",
      "Speed: 2.0ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 2 baseballs, 12.5ms\n",
      "Speed: 3.0ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 1 home plate, 10.5ms\n",
      "Speed: 1.7ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 10.8ms\n",
      "Speed: 3.1ms preprocess, 10.8ms inference, 0.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 1 home plate, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 1 baseball, 10.9ms\n",
      "Speed: 2.9ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 1 home plate, 10.2ms\n",
      "Speed: 1.8ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 10.9ms\n",
      "Speed: 2.8ms preprocess, 10.9ms inference, 0.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 1 home plate, 10.8ms\n",
      "Speed: 1.7ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 12.4ms\n",
      "Speed: 4.0ms preprocess, 12.4ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 18.8ms\n",
      "Speed: 2.4ms preprocess, 18.8ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 13.6ms\n",
      "Speed: 3.9ms preprocess, 13.6ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 1 home plate, 12.8ms\n",
      "Speed: 2.1ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 13.3ms\n",
      "Speed: 3.8ms preprocess, 13.3ms inference, 0.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 12.4ms\n",
      "Speed: 2.0ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 12.0ms\n",
      "Speed: 3.2ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 12.7ms\n",
      "Speed: 2.7ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 12.4ms\n",
      "Speed: 3.3ms preprocess, 12.4ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 12.3ms\n",
      "Speed: 2.0ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 12.1ms\n",
      "Speed: 3.2ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 12.2ms\n",
      "Speed: 2.0ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 11.9ms\n",
      "Speed: 3.2ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 12.4ms\n",
      "Speed: 2.1ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 1 baseball, 18.5ms\n",
      "Speed: 4.0ms preprocess, 18.5ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 12.2ms\n",
      "Speed: 2.0ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 12.2ms\n",
      "Speed: 3.4ms preprocess, 12.2ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 320x544 1 batter, 12.6ms\n",
      "Speed: 2.1ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 544)\n",
      "\n",
      "0: 736x1280 (no detections), 12.1ms\n",
      "Speed: 3.3ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "Video saved as output.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load trained models\n",
    "batter_homeplate_model = YOLO(\"runs/detect/train12/weights/best.pt\")  # Detects batter & home plate\n",
    "baseball_model = YOLO(\"../runs/detect/train13/weights/best.pt\")  # Detects baseball\n",
    "\n",
    "# Load input video\n",
    "video_path = \"pitch_vid_test3.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video properties\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Define VideoWriter to save output video\n",
    "output_path = \"output.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "frame_count = 0\n",
    "ball_positions = []  # Store ball positions over frames\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1  # Track frame count\n",
    "\n",
    "    # Run detection on batter & home plate\n",
    "    batter_results = batter_homeplate_model(frame)[0]\n",
    "    baseball_results = baseball_model(frame, conf=0.1, imgsz=1280)[0]\n",
    "\n",
    "    batter_bbox, plate_bbox, ball_bbox = None, None, None\n",
    "\n",
    "    # Extract batter & home plate bounding boxes\n",
    "    for r in batter_results.boxes.data:\n",
    "        class_id = int(r[-1])  # Class ID is the last value\n",
    "        conf = r[-2]  # Confidence score\n",
    "        if conf < 0.3:  # Ignore low-confidence detections\n",
    "            continue\n",
    "        if class_id == 0:  # Batter\n",
    "            batter_bbox = r[:4].tolist()\n",
    "        elif class_id == 1:  # Home Plate\n",
    "            plate_bbox = r[:4].tolist()\n",
    "\n",
    "    # Extract baseball bounding box\n",
    "    for r in baseball_results.boxes.data:\n",
    "        conf = r[-2]\n",
    "        if conf < 0.3:  # Ignore low-confidence detections\n",
    "            continue\n",
    "        if int(r[-1]) == 0:  # Baseball\n",
    "            ball_bbox = r[:4].tolist()\n",
    "\n",
    "    # Draw detected objects\n",
    "    if batter_bbox:\n",
    "        cv2.rectangle(frame, (int(batter_bbox[0]), int(batter_bbox[1])),\n",
    "                      (int(batter_bbox[2]), int(batter_bbox[3])), (255, 255, 0), 2)  # Yellow for Batter\n",
    "\n",
    "    if plate_bbox:\n",
    "        cv2.rectangle(frame, (int(plate_bbox[0]), int(plate_bbox[1])),\n",
    "                      (int(plate_bbox[2]), int(plate_bbox[3])), (255, 0, 255), 2)  # Purple for Home Plate\n",
    "\n",
    "    if ball_bbox:\n",
    "        ball_center_x = (ball_bbox[0] + ball_bbox[2]) / 2\n",
    "        ball_center_y = (ball_bbox[1] + ball_bbox[3]) / 2\n",
    "        cv2.circle(frame, (int(ball_center_x), int(ball_center_y)), 5, (0, 255, 0), -1)  # Green for Ball\n",
    "\n",
    "        # Store ball position for tracking\n",
    "        ball_positions.append((ball_center_x, ball_center_y))\n",
    "\n",
    "    # Compute Strike Zone if batter & home plate are detected\n",
    "    if batter_bbox and plate_bbox:\n",
    "        batter_top = batter_bbox[1]\n",
    "        batter_bottom = batter_bbox[3]\n",
    "\n",
    "        # Adjusted Strike Zone Boundaries (Smaller Box)\n",
    "        strike_zone_top = batter_top + (batter_bottom - batter_top) * 0.3\n",
    "        strike_zone_bottom = batter_top + (batter_bottom - batter_top) * 0.7\n",
    "        strike_zone_x_min = plate_bbox[0] - 10\n",
    "        strike_zone_x_max = plate_bbox[2] + 10\n",
    "\n",
    "        # Draw Strike Zone\n",
    "        cv2.rectangle(frame, (int(strike_zone_x_min), int(strike_zone_top)),\n",
    "                      (int(strike_zone_x_max), int(strike_zone_bottom)), (255, 0, 0), 2)  # Blue for Strike Zone\n",
    "\n",
    "    # Check if the ball has passed the batter before classification\n",
    "    if ball_positions and batter_bbox:\n",
    "        last_ball_x, last_ball_y = ball_positions[-1]  # Get latest ball position\n",
    "        batter_x = batter_bbox[0]  # Get batter's X position\n",
    "\n",
    "        if (strike_zone_x_min <= last_ball_x <= strike_zone_x_max and\n",
    "            strike_zone_top <= last_ball_y <= strike_zone_bottom):\n",
    "            result = \"Strike!\"\n",
    "            color = (0, 255, 0)  # Green for Strike\n",
    "        else:\n",
    "            result = \"Ball!\"\n",
    "            color = (0, 0, 255)  # Red for Ball\n",
    "\n",
    "        # Display result\n",
    "        cv2.putText(frame, result, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "        print(result)\n",
    "\n",
    "    # Write frame to output video file\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(f\"Video saved as {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab95121b-1872-4933-a881-d685202f626d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
